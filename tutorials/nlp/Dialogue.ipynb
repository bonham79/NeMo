{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaosjY4rGRNH"
   },
   "source": [
    "# Installing NeMo from source\n",
    "\n",
    "\n",
    "You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n",
    "\n",
    "Instructions for setting up Colab are as follows:\n",
    "1. Open a new Python 3 notebook.\n",
    "2. Import this notebook from GitHub (File -> Upload Notebook -> \"GITHUB\" tab -> copy/paste GitHub URL)\n",
    "3. Connect to an instance with a GPU (Runtime -> Change runtime type -> select \"GPU\" for hardware accelerator)\n",
    "4. Run the cell below to set up dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goQzOSflEq27"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "BRANCH = 'main'\n",
    "!apt-get update && apt-get install -y libsndfile1 ffmpeg\n",
    "!git clone https://github.com/NVIDIA/NeMo --branch $BRANCH\n",
    "os.chdir('NeMo')\n",
    "!./reinstall.sh\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjQ_z_xQMDIb"
   },
   "source": [
    "# Overview\n",
    "\n",
    "There are four tasks as part of this tutorial\n",
    "\n",
    "1. Intent and Slot Classification using Assistant Dataset and a BERT model\n",
    "2. Intent Classification using Schema Guided Dialogue Dataset and a GPT2 model\n",
    "3. Answer Extender using MS Marco NLGen Dataset and a BART model\n",
    "4. Zero Shot Slot Model using Assistant Dataset\n",
    "\n",
    "Feel free to skip to the task that interests you most after installing NeMo from source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS-zwy8tEq2_"
   },
   "source": [
    "# 1. Intent and Slot Classification using Assistant Dataset\n",
    "\n",
    "## 1.1 Task Description\n",
    "\n",
    "**Joint Intent and Slot classification** - is a task of classifying an Intent and detecting all relevant Slots (Entities)\n",
    "for this Intent in a query.\n",
    "For example, in the query:  `What is the weather in Santa Clara tomorrow morning?`, we would like to classify the query\n",
    "as a `weather` Intent, and detect `Santa Clara` as a `location` slot and `tomorrow morning` as a `date_time` slot.\n",
    "Intents and Slots names are usually task specific and defined as labels in the training data.\n",
    "This is a fundamental step that is executed in any task-driven Conversational Assistant.\n",
    "\n",
    "Our model enables to train and then detect both of these tasks together.\n",
    "\n",
    "Note: There is a similar model available at [Joint Intent Slot Classification Colab](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/nlp/Joint_Intent_and_Slot_Classification.ipynb). However, this model only support BERT style models while the model in this tutorial supports other types of models such as GPT2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJk_UAyeEq3B"
   },
   "source": [
    "\n",
    "## 1.2 Download Assistant dataset and convert to NeMo format\n",
    "\n",
    "This is a virtual assistant interaction data set that can be downloaded from here: https://github.com/xliuhw/NLU-Evaluation-Data.\n",
    "There are about 10K training and 1K testing queries which cover 64 various Intents and 55 Slots. \n",
    "\n",
    "An example is:\n",
    "\n",
    "* utterance: what alarms have i set for tomorrow \n",
    "* intent: alarm_query\n",
    "* slots: date(tomorrow)\n",
    "\n",
    "\n",
    "Note: While only the assistant dataset is used here, import_dataset.py is also compatible with ATIS and SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjOVdGX2Eq3D"
   },
   "outputs": [],
   "source": [
    "# download and unzip the example dataset from github\n",
    "!wget https://github.com/xliuhw/NLU-Evaluation-Data/archive/master.zip\n",
    "!unzip master.zip\n",
    "# convert the dataset to the NeMo format\n",
    "!python NeMo/scripts/dataset_processing/nlp/intent_and_slot/import_datasets.py --dataset_name=assistant --source_data_dir=./NLU-Evaluation-Data-master --target_data_dir=./assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n81deZsEq3G"
   },
   "source": [
    "## 1.3 Training and/or Testing the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoYc_8jhEq3G"
   },
   "outputs": [],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=True \\\n",
    "  model.dataset.data_dir='./assistant' \\\n",
    "  model.dataset.dialogues_example_dir='./assistant_bert_examples' \\\n",
    "  model.dataset.task='assistant' \\\n",
    "  model.language_model.pretrained_model_name='bert-base-uncased' \\\n",
    "  exp_manager.create_wandb_logger=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaPmHjayEbg8"
   },
   "source": [
    "**Results after 3 epochs**\n",
    "\n",
    "Intent report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    alarm_query (label_id: 0)                              100.00      94.44      97.14         18\n",
    "    alarm_remove (label_id: 1)                             100.00      90.91      95.24         11\n",
    "    alarm_set (label_id: 2)                                 94.12      94.12      94.12         17\n",
    "    audio_volume_down (label_id: 3)                         75.00      42.86      54.55          7\n",
    "    audio_volume_mute (label_id: 4)                        100.00      92.86      96.30         14\n",
    "    audio_volume_up (label_id: 5)                           72.22     100.00      83.87         13\n",
    "    calendar_query (label_id: 6)                            87.50      77.78      82.35         18\n",
    "    calendar_remove (label_id: 7)                           94.44     100.00      97.14         17\n",
    "    calendar_set (label_id: 8)                              94.44      94.44      94.44         18\n",
    "    cooking_recipe (label_id: 9)                            85.71      70.59      77.42         17\n",
    "    datetime_convert (label_id: 10)                         88.89     100.00      94.12          8\n",
    "    datetime_query (label_id: 11)                           89.47     100.00      94.44         17\n",
    "    email_addcontact (label_id: 12)                         80.00     100.00      88.89          8\n",
    "    email_query (label_id: 13)                             100.00      83.33      90.91         18\n",
    "    email_querycontact (label_id: 14)                       78.95      88.24      83.33         17\n",
    "    email_sendemail (label_id: 15)                          94.44      94.44      94.44         18\n",
    "    general_affirm (label_id: 16)                          100.00     100.00     100.00         17\n",
    "    general_commandstop (label_id: 17)                     100.00     100.00     100.00         18\n",
    "    general_confirm (label_id: 18)                         100.00     100.00     100.00         17\n",
    "    general_dontcare (label_id: 19)                        100.00     100.00     100.00         18\n",
    "    general_explain (label_id: 20)                         100.00     100.00     100.00         17\n",
    "    general_joke (label_id: 21)                             91.67     100.00      95.65         11\n",
    "    general_negate (label_id: 22)                          100.00     100.00     100.00         18\n",
    "    general_praise (label_id: 23)                          100.00     100.00     100.00         17\n",
    "    general_quirky (label_id: 24)                           60.00      50.00      54.55         18\n",
    "    general_repeat (label_id: 25)                          100.00     100.00     100.00         17\n",
    "    iot_cleaning (label_id: 26)                            100.00     100.00     100.00         15\n",
    "    iot_coffee (label_id: 27)                               85.71     100.00      92.31         18\n",
    "    iot_hue_lightchange (label_id: 28)                     100.00      94.12      96.97         17\n",
    "    iot_hue_lightdim (label_id: 29)                        100.00     100.00     100.00         12\n",
    "    iot_hue_lightoff (label_id: 30)                        100.00     100.00     100.00         17\n",
    "    iot_hue_lighton (label_id: 31)                         100.00      50.00      66.67          4\n",
    "    iot_hue_lightup (label_id: 32)                          84.62      91.67      88.00         12\n",
    "    iot_wemo_off (label_id: 33)                            100.00     100.00     100.00          9\n",
    "    iot_wemo_on (label_id: 34)                             100.00      85.71      92.31          7\n",
    "    lists_createoradd (label_id: 35)                        90.00     100.00      94.74         18\n",
    "    lists_query (label_id: 36)                             100.00      94.12      96.97         17\n",
    "    lists_remove (label_id: 37)                             88.89      88.89      88.89         18\n",
    "    music_likeness (label_id: 38)                          100.00      93.75      96.77         16\n",
    "    music_query (label_id: 39)                             100.00     100.00     100.00         17\n",
    "    music_settings (label_id: 40)                           77.78     100.00      87.50          7\n",
    "    news_query (label_id: 41)                               72.73      88.89      80.00         18\n",
    "    play_audiobook (label_id: 42)                          100.00     100.00     100.00         17\n",
    "    play_game (label_id: 43)                                93.75      83.33      88.24         18\n",
    "    play_music (label_id: 44)                               85.00     100.00      91.89         17\n",
    "    play_podcasts (label_id: 45)                           100.00      88.89      94.12         18\n",
    "    play_radio (label_id: 46)                               84.21      94.12      88.89         17\n",
    "    qa_currency (label_id: 47)                              85.00      94.44      89.47         18\n",
    "    qa_definition (label_id: 48)                            89.47     100.00      94.44         17\n",
    "    qa_factoid (label_id: 49)                               64.00      88.89      74.42         18\n",
    "    qa_maths (label_id: 50)                                 84.62      84.62      84.62         13\n",
    "    qa_stock (label_id: 51)                                 87.50      77.78      82.35         18\n",
    "    recommendation_events (label_id: 52)                    87.50      82.35      84.85         17\n",
    "    recommendation_locations (label_id: 53)                 83.33      83.33      83.33         18\n",
    "    recommendation_movies (label_id: 54)                   100.00      60.00      75.00         10\n",
    "    social_post (label_id: 55)                             100.00      94.12      96.97         17\n",
    "    social_query (label_id: 56)                            100.00      82.35      90.32         17\n",
    "    takeaway_order (label_id: 57)                           92.31      70.59      80.00         17\n",
    "    takeaway_query (label_id: 58)                           93.75      83.33      88.24         18\n",
    "    transport_query (label_id: 59)                          81.25      76.47      78.79         17\n",
    "    transport_taxi (label_id: 60)                          100.00     100.00     100.00         16\n",
    "    transport_ticket (label_id: 61)                         85.00      94.44      89.47         18\n",
    "    transport_traffic (label_id: 62)                        93.75      88.24      90.91         17\n",
    "    weather_query (label_id: 63)                            89.47     100.00      94.44         17\n",
    "    -------------------\n",
    "    micro avg                                               91.16      91.16      91.16        996\n",
    "    macro avg                                               91.66      90.44      90.48        996\n",
    "    weighted avg                                            91.72      91.16      91.04        996\n",
    "```\n",
    "Slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    alarm_type (label_id: 0)                                 0.00       0.00       0.00          2\n",
    "    app_name (label_id: 1)                                   0.00       0.00       0.00          1\n",
    "    artist_name (label_id: 2)                               17.39      80.00      28.57          5\n",
    "    audiobook_author (label_id: 3)                           0.00       0.00       0.00          0\n",
    "    audiobook_name (label_id: 4)                            64.52      74.07      68.97         27\n",
    "    business_name (label_id: 5)                             81.48      84.62      83.02         52\n",
    "    business_type (label_id: 6)                             80.00      80.00      80.00         20\n",
    "    change_amount (label_id: 7)                             57.14      66.67      61.54          6\n",
    "    coffee_type (label_id: 8)                              100.00      33.33      50.00          3\n",
    "    color_type (label_id: 9)                                75.00      92.31      82.76         13\n",
    "    cooking_type (label_id: 10)                              0.00       0.00       0.00          1\n",
    "    currency_name (label_id: 11)                           100.00      96.43      98.18         28\n",
    "    date (label_id: 12)                                     87.88      87.22      87.55        133\n",
    "    definition_word (label_id: 13)                          85.00      85.00      85.00         20\n",
    "    device_type (label_id: 14)                              84.75      76.92      80.65         65\n",
    "    drink_type (label_id: 15)                                0.00       0.00       0.00          0\n",
    "    email_address (label_id: 16)                            64.29     100.00      78.26          9\n",
    "    email_folder (label_id: 17)                            100.00      50.00      66.67          2\n",
    "    event_name (label_id: 18)                               80.00      75.00      77.42         64\n",
    "    food_type (label_id: 19)                                84.38      77.14      80.60         35\n",
    "    game_name (label_id: 20)                                93.55      78.38      85.29         37\n",
    "    game_type (label_id: 21)                                 0.00       0.00       0.00          0\n",
    "    general_frequency (label_id: 22)                         0.00       0.00       0.00          9\n",
    "    house_place (label_id: 23)                              80.95      91.89      86.08         37\n",
    "    ingredient (label_id: 24)                                0.00       0.00       0.00          1\n",
    "    joke_type (label_id: 25)                               100.00     100.00     100.00          5\n",
    "    list_name (label_id: 26)                                89.29      69.44      78.12         36\n",
    "    meal_type (label_id: 27)                                 0.00       0.00       0.00          3\n",
    "    media_type (label_id: 28)                               78.95      83.33      81.08         36\n",
    "    movie_name (label_id: 29)                                0.00       0.00       0.00          1\n",
    "    movie_type (label_id: 30)                                0.00       0.00       0.00          0\n",
    "    music_album (label_id: 31)                               0.00       0.00       0.00          0\n",
    "    music_descriptor (label_id: 32)                          0.00       0.00       0.00          2\n",
    "    music_genre (label_id: 33)                              81.82      90.00      85.71         10\n",
    "    news_topic (label_id: 34)                               80.00      30.77      44.44         13\n",
    "    order_type (label_id: 35)                              100.00      42.11      59.26         19\n",
    "    person (label_id: 36)                                   70.79     100.00      82.89         63\n",
    "    personal_info (label_id: 37)                            76.19      94.12      84.21         17\n",
    "    place_name (label_id: 38)                               82.86      84.47      83.65        103\n",
    "    player_setting (label_id: 39)                           75.00      42.86      54.55          7\n",
    "    playlist_name (label_id: 40)                             0.00       0.00       0.00          3\n",
    "    podcast_descriptor (label_id: 41)                       92.31      54.55      68.57         22\n",
    "    podcast_name (label_id: 42)                             66.67      16.67      26.67         12\n",
    "    radio_name (label_id: 43)                               94.87      94.87      94.87         39\n",
    "    relation (label_id: 44)                                 90.91      90.91      90.91         11\n",
    "    song_name (label_id: 45)                               100.00       6.67      12.50         15\n",
    "    time (label_id: 46)                                     77.57      84.69      80.98         98\n",
    "    time_zone (label_id: 47)                                44.44     100.00      61.54          4\n",
    "    timeofday (label_id: 48)                                86.96      80.00      83.33         25\n",
    "    transport_agency (label_id: 49)                         80.00      57.14      66.67          7\n",
    "    transport_descriptor (label_id: 50)                      0.00       0.00       0.00          5\n",
    "    transport_name (label_id: 51)                            0.00       0.00       0.00          0\n",
    "    transport_type (label_id: 52)                           88.89     100.00      94.12         40\n",
    "    weather_descriptor (label_id: 53)                       87.50      87.50      87.50          8\n",
    "    O (label_id: 54)                                        97.07      97.52      97.30       5408\n",
    "    -------------------\n",
    "    micro avg                                               94.24      94.24      94.24       6582\n",
    "    macro avg                                               64.87      59.93      59.17       6582\n",
    "    weighted avg                                            94.23      94.24      93.95       6582\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-44x5PqyrOeQ"
   },
   "source": [
    "## 1.4 (Optional) To train/ test a GPT2 model on the assistant dataset, run the cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyqQbpR4rNHT"
   },
   "outputs": [],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "# model.tokenizer.special_tokens=\"{pad_token:'<|endoftext|>'}\": gpt2 doesn't specify a pad token, therefore using its EOS token as the pad token\n",
    "# model.dataset.target_template=with_slots: this perform slot filling with intent classification\n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=True \\\n",
    "  model.dataset.data_dir='./assistant' \\\n",
    "  model.dataset.dialogues_example_dir='./assistant_gpt2_examples' \\\n",
    "  model.dataset.task='assistant' \\\n",
    "  model.language_model.pretrained_model_name='gpt2' \\\n",
    "  trainer.max_epochs=1 \\\n",
    "  model.tokenizer.special_tokens=\"{pad_token:'<|endoftext|>'}\" \\\n",
    "  model.dataset.target_template=with_slots \\\n",
    "  model.dataset.eval_mode=generation \\\n",
    "  exp_manager.create_wandb_logger=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbQ-6TVM1yQg"
   },
   "source": [
    "**After 1 epoch:**\n",
    "\n",
    "More epochs would be helpful\n",
    "\n",
    "Intent report:\n",
    "\n",
    "  ```\n",
    "  label                                                precision    recall       f1           support   \n",
    "    transport query (label_id: 0)                           72.73      84.21      78.05         19\n",
    "    weather query (label_id: 1)                             94.74      94.74      94.74         19\n",
    "    play game (label_id: 2)                                 92.86      68.42      78.79         19\n",
    "    qa currency (label_id: 3)                              100.00     100.00     100.00         19\n",
    "    qa maths (label_id: 4)                                 100.00     100.00     100.00         14\n",
    "    iot wemo off (label_id: 5)                              75.00     100.00      85.71          9\n",
    "    datetime convert (label_id: 6)                          46.67      87.50      60.87          8\n",
    "    email addcontact (label_id: 7)                          70.00      87.50      77.78          8\n",
    "    music likeness (label_id: 8)                            57.89      61.11      59.46         18\n",
    "    music query (label_id: 9)                               78.57      57.89      66.67         19\n",
    "    general negate (label_id: 10)                           95.00     100.00      97.44         19\n",
    "    email sendemail (label_id: 11)                          92.86      68.42      78.79         19\n",
    "    general affirm (label_id: 12)                           95.00     100.00      97.44         19\n",
    "    play audiobook (label_id: 13)                           57.69      78.95      66.67         19\n",
    "    general praise (label_id: 14)                          100.00      94.74      97.30         19\n",
    "    alarm set (label_id: 15)                                85.71      94.74      90.00         19\n",
    "    general explain (label_id: 16)                         100.00      89.47      94.44         19\n",
    "    iot wemo on (label_id: 17)                              83.33      71.43      76.92          7\n",
    "    cooking recipe (label_id: 18)                           90.00      94.74      92.31         19\n",
    "    music settings (label_id: 19)                           60.00      42.86      50.00          7\n",
    "    social post (label_id: 20)                              84.21      84.21      84.21         19\n",
    "    recommendation events (label_id: 21)                    72.73      84.21      78.05         19\n",
    "    audio volume up (label_id: 22)                          76.47     100.00      86.67         13\n",
    "    lists remove (label_id: 23)                             73.08     100.00      84.44         19\n",
    "    transport ticket (label_id: 24)                         94.74      94.74      94.74         19\n",
    "    general joke (label_id: 25)                            100.00     100.00     100.00         12\n",
    "    play podcasts (label_id: 26)                            94.12      84.21      88.89         19\n",
    "    iot hue lightchange (label_id: 27)                      85.71      63.16      72.73         19\n",
    "    audio volume mute (label_id: 28)                        84.62      73.33      78.57         15\n",
    "    general dontcare (label_id: 29)                         95.00     100.00      97.44         19\n",
    "    qa definition (label_id: 30)                            77.27      89.47      82.93         19\n",
    "    email querycontact (label_id: 31)                       58.33      73.68      65.12         19\n",
    "    general commandstop (label_id: 32)                     100.00     100.00     100.00         19\n",
    "    calendar remove (label_id: 33)                          94.44      89.47      91.89         19\n",
    "    news query (label_id: 34)                              100.00      57.89      73.33         19\n",
    "    calendar query (label_id: 35)                           63.16      63.16      63.16         19\n",
    "    social query (label_id: 36)                             88.24      83.33      85.71         18\n",
    "    transport traffic (label_id: 37)                        90.48     100.00      95.00         19\n",
    "    transport taxi (label_id: 38)                          100.00      94.44      97.14         18\n",
    "    alarm query (label_id: 39)                             100.00      94.74      97.30         19\n",
    "    iot hue lightoff (label_id: 40)                         88.89      84.21      86.49         19\n",
    "    takeaway order (label_id: 41)                           81.25      68.42      74.29         19\n",
    "    iot coffee (label_id: 42)                              100.00      94.74      97.30         19\n",
    "    recommendation movies (label_id: 43)                    75.00      90.00      81.82         10\n",
    "    iot hue lightup (label_id: 44)                          78.57      78.57      78.57         14\n",
    "    email query (label_id: 45)                              85.71      94.74      90.00         19\n",
    "    lists createoradd (label_id: 46)                        82.35      73.68      77.78         19\n",
    "    play radio (label_id: 47)                               84.21      84.21      84.21         19\n",
    "    audio volume down (label_id: 48)                       100.00      87.50      93.33          8\n",
    "    general quirky (label_id: 49)                           30.00      15.79      20.69         19\n",
    "    play music (label_id: 50)                               71.43      52.63      60.61         19\n",
    "    qa stock (label_id: 51)                                 90.48     100.00      95.00         19\n",
    "    iot cleaning (label_id: 52)                             93.33      87.50      90.32         16\n",
    "    iot hue lightdim (label_id: 53)                        100.00     100.00     100.00         12\n",
    "    recommendation locations (label_id: 54)                100.00      89.47      94.44         19\n",
    "    general repeat (label_id: 55)                          100.00     100.00     100.00         19\n",
    "    takeaway query (label_id: 56)                           77.27      89.47      82.93         19\n",
    "    alarm remove (label_id: 57)                            100.00     100.00     100.00         11\n",
    "    datetime query (label_id: 58)                           75.00      63.16      68.57         19\n",
    "    iot hue lighton (label_id: 59)                          60.00     100.00      75.00          3\n",
    "    qa factoid (label_id: 60)                               50.00      57.89      53.66         19\n",
    "    calendar set (label_id: 61)                             75.00      78.95      76.92         19\n",
    "    general confirm (label_id: 62)                         100.00     100.00     100.00         19\n",
    "    lists query (label_id: 63)                              66.67      73.68      70.00         19\n",
    "    label_id: 64                                             0.00       0.00       0.00          0\n",
    "    -------------------\n",
    "    micro avg                                               83.55      83.55      83.55       1076\n",
    "    macro avg                                               83.53      83.93      83.01       1076\n",
    "    weighted avg                                            84.26      83.55      83.30       1076\n",
    "    \n",
    "```\n",
    "\n",
    "```\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "       Test metric             DataLoader 0\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "        intent_f1            83.55018615722656\n",
    "    intent_precision         83.55018615722656\n",
    "      intent_recall          83.55018615722656\n",
    "         slot_f1             73.99985919756773\n",
    "slot_joint_goal_accuracy     65.89219330855019\n",
    "     slot_precision          73.85223048327137\n",
    "       slot_recall           74.14807930607186\n",
    "  test_intent_accuracy       83.55018587360595\n",
    "     test_loss_epoch       0.019178826361894608\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd42arYoEq3J"
   },
   "source": [
    "# 2. Schema Guided Dialogue (SGD)\n",
    "\n",
    "## 2.1 Task Description\n",
    "---\n",
    "\n",
    "SGD is a multi-domain intent classification dataset from Google with close to 100k examples.\n",
    "\n",
    "An example is:\n",
    "\n",
    "* utterance: I will be eating there at 11:30 am so make the reservation for then.\n",
    "* intent: ReserveRestaurant\n",
    "* slots: {\"time\": \"11:30 am\"}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neH8rXwjEq3J"
   },
   "source": [
    "## 2.2 Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgD8eavfJ5pi"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/google-research-datasets/dstc8-schema-guided-dialogue.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G7uPrUpEq3J"
   },
   "source": [
    "## 2.3 Training and/or Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqo-rwQlEq3K"
   },
   "outputs": [],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "# model.tokenizer.special_tokens=\"{pad_token:'<|endoftext|>'}\": gpt2 doesn't specify a pad token, therefore using its EOS token as the pad token\n",
    "\n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=True \\\n",
    "  model.dataset.data_dir='./dstc8-schema-guided-dialogue' \\\n",
    "  model.dataset.dialogues_example_dir='./sgd_gpt2_predictions' \\\n",
    "  model.dataset.task='sgd' \\\n",
    "  model.language_model.pretrained_model_name='gpt2' \\\n",
    "  trainer.max_epochs=1 \\\n",
    "  model.tokenizer.special_tokens=\"{pad_token:'<|endoftext|>'}\" \\\n",
    "  exp_manager.create_wandb_logger=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGDlV5HvI2PQ"
   },
   "outputs": [],
   "source": [
    "!ls sgd_gpt2_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8g0f5KDTu9K"
   },
   "source": [
    "**After 1 epoch:**\n",
    "\n",
    "More epochs would needed to reach convergence.\n",
    "\n",
    "\n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    check balance (label_id: 0)                              0.00       0.00       0.00          0\n",
    "    find trains (label_id: 1)                               80.20      91.95      85.68        348\n",
    "    make payment (label_id: 2)                              83.12      28.07      41.97        228\n",
    "    book appointment (label_id: 3)                          86.93      87.15      87.04        397\n",
    "    get cars available (label_id: 4)                        96.88      90.51      93.58        274\n",
    "    get event dates (label_id: 5)                            0.00       0.00       0.00          0\n",
    "    buy bus ticket (label_id: 6)                            78.61      91.33      84.49        173\n",
    "    add event (label_id: 7)                                  0.00       0.00       0.00          0\n",
    "    get alarms (label_id: 8)                                58.33      77.78      66.67         45\n",
    "    reserve car (label_id: 9)                               83.75      72.43      77.68        185\n",
    "    get events (label_id: 10)                                0.00       0.00       0.00          0\n",
    "    reserve roundtrip flights (label_id: 11)                 0.00       0.00       0.00          0\n",
    "    lookup music (label_id: 12)                             89.83      86.89      88.33         61\n",
    "    book house (label_id: 13)                               91.13      92.50      91.81        200\n",
    "    search oneway flight (label_id: 14)                     74.77      47.70      58.25        174\n",
    "    buy event tickets (label_id: 15)                        72.19      95.31      82.15        128\n",
    "    find apartment (label_id: 16)                            0.00       0.00       0.00          0\n",
    "    schedule visit (label_id: 17)                           77.27      66.06      71.23        386\n",
    "    play media (label_id: 18)                               92.94      86.81      89.77         91\n",
    "    get ride (label_id: 19)                                 99.41      98.82      99.12        170\n",
    "    reserve oneway flight (label_id: 20)                     0.00       0.00       0.00          0\n",
    "    find bus (label_id: 21)                                 96.64      87.53      91.86        361\n",
    "    find restaurants (label_id: 22)                         77.14      91.22      83.59        148\n",
    "    get times for movie (label_id: 23)                       0.00       0.00       0.00          0\n",
    "    transfer money (label_id: 24)                            0.00       0.00       0.00          0\n",
    "    request payment (label_id: 25)                          46.71      63.39      53.79        112\n",
    "    play movie (label_id: 26)                              100.00      65.11      78.87        321\n",
    "    search house (label_id: 27)                             97.91      91.83      94.77        306\n",
    "    search roundtrip flights (label_id: 28)                 67.49      82.41      74.21        199\n",
    "    find provider (label_id: 29)                            95.11      90.53      92.77        602\n",
    "    find attractions (label_id: 30)                        100.00      89.01      94.19         91\n",
    "    reserve hotel (label_id: 31)                            56.75      97.04      71.62        169\n",
    "    lookup song (label_id: 32)                               0.00       0.00       0.00          0\n",
    "    add alarm (label_id: 33)                                95.68      60.18      73.89        221\n",
    "    find home by area (label_id: 34)                        48.95      59.79      53.83        194\n",
    "    get available time (label_id: 35)                        0.00       0.00       0.00          0\n",
    "    buy movie tickets (label_id: 36)                       100.00      29.39      45.42        473\n",
    "    reserve restaurant (label_id: 37)                       95.71      84.80      89.92        342\n",
    "    find movies (label_id: 38)                              62.40      97.61      76.14        335\n",
    "    get weather (label_id: 39)                             100.00      87.69      93.44        195\n",
    "    search hotel (label_id: 40)                             99.35      52.60      68.78        289\n",
    "    find events (label_id: 41)                              99.57      82.56      90.27        281\n",
    "    play song (label_id: 42)                                 0.00       0.00       0.00          0\n",
    "    rent movie (label_id: 43)                                0.00       0.00       0.00          0\n",
    "    get train tickets (label_id: 44)                        45.83       5.56       9.91        198\n",
    "    none (label_id: 45)                                     55.77      98.90      71.32        728\n",
    "    label_id: 46                                             0.00       0.00       0.00          0\n",
    "    -------------------\n",
    "    micro avg                                               77.23      77.23      77.23       8425\n",
    "    macro avg                                               82.01      76.68      76.56       8425\n",
    "    weighted avg                                            83.23      77.23      76.86       8425\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUJb-9VLLBXo"
   },
   "source": [
    "# 3. MS Marco\n",
    "\n",
    "## Task Description\n",
    "\n",
    "MS Marco NLGen is a dataset from Microsoft that takes extracted answers and questions and output fluent answers.\n",
    "\n",
    "An example is \n",
    "\n",
    "\n",
    "*   question: What county is Nine Mile in?\n",
    "*   extracted_answer: Onondaga\n",
    "*   fluent_answer: Nine Mile is in Onondaga county.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtXEKG_UQU9u"
   },
   "source": [
    "## Download and unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9avsZ1CEq3K"
   },
   "outputs": [],
   "source": [
    "!mkdir ms_marco\n",
    "os.chdir('ms_marco')\n",
    "!wget https://msmarco.blob.core.windows.net/msmarco/train_v2.1.json.gz\n",
    "!wget https://msmarco.blob.core.windows.net/msmarco/dev_v2.1.json.gz\n",
    "\n",
    "!gunzip train_v2.1.json.gz\n",
    "!gunzip dev_v2.1.json.gz\n",
    "\n",
    "!python ../NeMo/examples/nlp/dialogue/remove_ms_marco_samples_without_wellFormedAnswers.py --filename train_v2.1.json \n",
    "!python ../NeMo/examples/nlp/dialogue/remove_ms_marco_samples_without_wellFormedAnswers.py --filename dev_v2.1.json \n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7UZ9R8gQTFo"
   },
   "source": [
    "## Training and/or Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwGQCwbvRf2m"
   },
   "outputs": [],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "\n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=True \\\n",
    "  model.dataset.dialogues_example_dir='./marco_bart_predictions' \\\n",
    "  model.dataset.data_dir='./ms_marco' \\\n",
    "  model.save_model=True \\\n",
    "  model.dataset.debug_mode=True \\\n",
    "  model.dataset.task='ms_marco' \\\n",
    "  model.language_model.pretrained_model_name='facebook/bart-base' \\\n",
    "  trainer.max_epochs=1 \\\n",
    "  model.dataset.debug_mode=False \\\n",
    "  exp_manager.create_wandb_logger=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL7ekAOZ2abi"
   },
   "source": [
    "**After 1 epoch:**\n",
    "\n",
    "Train more epochs for optimal performance\n",
    "\n",
    "```\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "       Test metric             DataLoader 0\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "          bleu               65.46179962158203\n",
    "           f1                78.24439835896995\n",
    "        precision            81.92473076099847\n",
    "         recall              76.72508929408436\n",
    "      test_accuracy         25.563487607283225\n",
    "        test_loss           0.4419259166606655\n",
    "     test_loss_epoch        0.4420809745788574\n",
    "        test_ppl            1.5557004846779854\n",
    "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Zero Shot Slot Filling using Assistant Dataset\n",
    "\n",
    "## 4.1 Task Description\n",
    "\n",
    "**Zero Shot Slot Filling** - is a task of detecting mention from BIO slot filling and classifying the associated slot class (Entities)\n",
    "\n",
    "For example, in the query:  `What is the weather in Santa Clara tomorrow morning?`, we would like to detect `Santa Clara` as a `location` slot and `tomorrow morning` as a `date_time` slot.\n",
    "\n",
    "Slots names are usually task specific and defined as labels in the training data.\n",
    "This is a fundamental step that is executed in any task-driven Conversational Assistant.\n",
    "\n",
    "Our model enables to fine-tuned on in domain dataset and test. Also enables to transfer fine-tuned model to test out of domain dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Download Assistant dataset and convert to NeMo format\n",
    "\n",
    "(If you already download Assistant dataset at 1.2, please skip this section 4.2)\n",
    "\n",
    "This is a virtual assistant interaction data set that can be downloaded from here: https://github.com/xliuhw/NLU-Evaluation-Data.\n",
    "There are about 10K training and 1K testing queries which cover 64 various Intents and 55 Slots. \n",
    "\n",
    "An example is:\n",
    "\n",
    "* utterance: what alarms have i set for tomorrow \n",
    "* intent: alarm_query\n",
    "* slots: date(tomorrow)\n",
    "\n",
    "\n",
    "Note: While only the assistant dataset is used here, import_dataset.py is also compatible with ATIS and SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip the example dataset from github\n",
    "!wget https://github.com/xliuhw/NLU-Evaluation-Data/archive/master.zip\n",
    "!unzip master.zip\n",
    "# convert the dataset to the NeMo format\n",
    "!python NeMo/scripts/dataset_processing/nlp/intent_and_slot/import_datasets.py --dataset_name=assistant --source_data_dir=./NLU-Evaluation-Data-master --target_data_dir=./assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Pre-process the dataset and Generate slot class description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process dataset for zero shot slot filling\n",
    "!python NeMo/examples/nlp/dialogue/preprocess_for_zero_shot_slot_filling.py --preprocess_file_path ./assistant/ --dataset assistant\n",
    "\n",
    "# generate description of the slot class from pre-processed dataset\n",
    "!python NeMo/examples/nlp/dialogue/generate_description_for_zero_shot_slot_filling.py --preprocess_file_path ./assistant/with_entity/ --dataset assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Training and/or Testing the model in domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "# trainer.max_epochs: number of epochs for training\n",
    "# model.bio_slot_loss_weight: mention detection (BIO tagging) loss weight\n",
    "# model.nemo_path: the path that stores trained nemo model\n",
    "# model.optim.lr: learning rate for trianing\n",
    "# fine-tuned best overall f1 score in Assistant dataset at parameter: bio_slot_loss_weight=0.5, max_epochs=10, optim.lr=0.00001\n",
    "  \n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=True \\\n",
    "  model.dataset.data_dir=\"./assistant/with_entity\" \\\n",
    "  model.dataset.dialogues_example_dir=\"./assistant/with_entity_prediction\" \\\n",
    "  model.dataset.task='zero_shot_slot_filling' \\\n",
    "  model.language_model.pretrained_model_name='bert-base-uncased' \\\n",
    "  exp_manager.create_wandb_logger=False \\\n",
    "  trainer.max_epochs=10 \\\n",
    "  model.bio_slot_loss_weight=0.5 \\\n",
    "  model.nemo_path=\"nemo_experiments/assistant/assistant_0.5_0.5_epoch_10_lr_0.00001.nemo\" \\\n",
    "  model.optim.lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results after 10 epochs**\n",
    "\n",
    "BIO slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    0 (label_id: 0)                                         97.06      95.86      96.45       3404\n",
    "    1 (label_id: 1)                                         87.86      91.38      89.58        800\n",
    "    2 (label_id: 2)                                         86.23      87.60      86.91        629\n",
    "    -------------------\n",
    "    micro avg                                               94.04      94.04      94.04       4833\n",
    "    macro avg                                               90.38      91.61      90.98       4833\n",
    "    weighted avg                                            94.12      94.04      94.07       4833\n",
    "```\n",
    "Slot similarity report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    alarm type (label_id: 0)                                 0.00       0.00       0.00          0\n",
    "    app name (label_id: 1)                                  83.33     100.00      90.91          5\n",
    "    artist name (label_id: 2)                               88.89      72.73      80.00         11\n",
    "    audiobook author (label_id: 3)                         100.00     100.00     100.00          1\n",
    "    audiobook name (label_id: 4)                            69.23      90.00      78.26         10\n",
    "    business name (label_id: 5)                             92.68     100.00      96.20         38\n",
    "    business type (label_id: 6)                             89.47      94.44      91.89         18\n",
    "    change amount (label_id: 7)                             81.82     100.00      90.00          9\n",
    "    coffee type (label_id: 8)                              100.00      75.00      85.71          4\n",
    "    color type (label_id: 9)                               100.00      90.91      95.24         11\n",
    "    cooking type (label_id: 10)                              0.00       0.00       0.00          0\n",
    "    currency name (label_id: 11)                           100.00      94.44      97.14         18\n",
    "    date (label_id: 12)                                     95.06      93.90      94.48         82\n",
    "    definition word (label_id: 13)                         100.00     100.00     100.00         16\n",
    "    device type (label_id: 14)                              95.24     100.00      97.56         40\n",
    "    drink type (label_id: 15)                                0.00       0.00       0.00          0\n",
    "    email address (label_id: 16)                           100.00     100.00     100.00          4\n",
    "    email folder (label_id: 17)                            100.00     100.00     100.00          1\n",
    "    event name (label_id: 18)                               92.68      79.17      85.39         48\n",
    "    food type (label_id: 19)                                92.00      95.83      93.88         24\n",
    "    game name (label_id: 20)                               100.00      93.75      96.77         16\n",
    "    game type (label_id: 21)                                 0.00       0.00       0.00          0\n",
    "    general frequency (label_id: 22)                        75.00      60.00      66.67          5\n",
    "    house place (label_id: 23)                             100.00      95.83      97.87         24\n",
    "    ingredient (label_id: 24)                              100.00      50.00      66.67          4\n",
    "    joke type (label_id: 25)                               100.00     100.00     100.00          4\n",
    "    list name (label_id: 26)                                61.11      91.67      73.33         12\n",
    "    meal type (label_id: 27)                                 0.00       0.00       0.00          0\n",
    "    media type (label_id: 28)                               93.33      87.50      90.32         32\n",
    "    movie name (label_id: 29)                                0.00       0.00       0.00          0\n",
    "    movie type (label_id: 30)                                0.00       0.00       0.00          0\n",
    "    music album (label_id: 31)                               0.00       0.00       0.00          0\n",
    "    music descriptor (label_id: 32)                          0.00       0.00       0.00          2\n",
    "    music genre (label_id: 33)                              77.78     100.00      87.50          7\n",
    "    news topic (label_id: 34)                               85.71      66.67      75.00          9\n",
    "    order type (label_id: 35)                              100.00     100.00     100.00         17\n",
    "    person (label_id: 36)                                   86.67      97.50      91.76         40\n",
    "    personal info (label_id: 37)                            92.86     100.00      96.30         13\n",
    "    place name (label_id: 38)                               98.72      92.77      95.65         83\n",
    "    player setting (label_id: 39)                           33.33     100.00      50.00          1\n",
    "    playlist name (label_id: 40)                             0.00       0.00       0.00          1\n",
    "    podcast descriptor (label_id: 41)                      100.00      83.33      90.91          6\n",
    "    podcast name (label_id: 42)                            100.00      50.00      66.67          2\n",
    "    radio name (label_id: 43)                              100.00      83.33      90.91         12\n",
    "    relation (label_id: 44)                                 84.62      84.62      84.62         13\n",
    "    song name (label_id: 45)                                71.43      55.56      62.50          9\n",
    "    time (label_id: 46)                                     93.33      93.33      93.33         60\n",
    "    time zone (label_id: 47)                                71.43     100.00      83.33          5\n",
    "    timeofday (label_id: 48)                                92.59      96.15      94.34         26\n",
    "    transport agency (label_id: 49)                        100.00     100.00     100.00          9\n",
    "    transport descriptor (label_id: 50)                      0.00       0.00       0.00          0\n",
    "    transport name (label_id: 51)                          100.00     100.00     100.00          2\n",
    "    transport type (label_id: 52)                          100.00     100.00     100.00         34\n",
    "    weather descriptor (label_id: 53)                      100.00      83.33      90.91         12\n",
    "    other (label_id: 54)                                     0.00       0.00       0.00          0\n",
    "    -------------------\n",
    "    micro avg                                               91.88      91.88      91.88        800\n",
    "    macro avg                                               86.63      85.59      84.93        800\n",
    "    weighted avg                                            92.92      91.88      92.05        800\n",
    "```\n",
    "\n",
    "Overall slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    alarm type (label_id: 0)                                 0.00       0.00       0.00          0\n",
    "    app name (label_id: 1)                                  83.33      83.33      83.33          6\n",
    "    artist name (label_id: 2)                               87.50      66.67      75.68         21\n",
    "    audiobook author (label_id: 3)                          50.00     100.00      66.67          1\n",
    "    audiobook name (label_id: 4)                            50.00      83.33      62.50         18\n",
    "    business name (label_id: 5)                             86.44      98.08      91.89         52\n",
    "    business type (label_id: 6)                             68.00      70.83      69.39         24\n",
    "    change amount (label_id: 7)                             83.33      80.00      81.63         25\n",
    "    coffee type (label_id: 8)                              100.00      75.00      85.71          4\n",
    "    color type (label_id: 9)                                62.50      83.33      71.43         12\n",
    "    cooking type (label_id: 10)                              0.00       0.00       0.00          0\n",
    "    currency name (label_id: 11)                            95.65      88.00      91.67         25\n",
    "    date (label_id: 12)                                     83.61      91.07      87.18        112\n",
    "    definition word (label_id: 13)                         100.00     100.00     100.00         20\n",
    "    device type (label_id: 14)                              92.59      93.75      93.17         80\n",
    "    drink type (label_id: 15)                                0.00       0.00       0.00          0\n",
    "    email address (label_id: 16)                           100.00      71.43      83.33         14\n",
    "    email folder (label_id: 17)                            100.00     100.00     100.00          1\n",
    "    event name (label_id: 18)                               74.19      67.65      70.77         68\n",
    "    food type (label_id: 19)                                76.74      76.74      76.74         43\n",
    "    game name (label_id: 20)                               100.00      90.48      95.00         21\n",
    "    game type (label_id: 21)                                 0.00       0.00       0.00          0\n",
    "    general frequency (label_id: 22)                        42.86      33.33      37.50          9\n",
    "    house place (label_id: 23)                              94.12      96.97      95.52         33\n",
    "    ingredient (label_id: 24)                              100.00      16.67      28.57          6\n",
    "    joke type (label_id: 25)                               100.00     100.00     100.00          4\n",
    "    list name (label_id: 26)                                51.52      80.95      62.96         21\n",
    "    meal type (label_id: 27)                                 0.00       0.00       0.00          0\n",
    "    media type (label_id: 28)                               82.76      64.86      72.73         37\n",
    "    movie name (label_id: 29)                                0.00       0.00       0.00          0\n",
    "    movie type (label_id: 30)                                0.00       0.00       0.00          0\n",
    "    music album (label_id: 31)                               0.00       0.00       0.00          0\n",
    "    music descriptor (label_id: 32)                          0.00       0.00       0.00          3\n",
    "    music genre (label_id: 33)                              69.23     100.00      81.82          9\n",
    "    news topic (label_id: 34)                               73.33      64.71      68.75         17\n",
    "    order type (label_id: 35)                               66.67      94.12      78.05         17\n",
    "    person (label_id: 36)                                   76.56      96.08      85.22         51\n",
    "    personal info (label_id: 37)                            86.67      68.42      76.47         19\n",
    "    place name (label_id: 38)                               93.86      80.45      86.64        133\n",
    "    player setting (label_id: 39)                           12.50     100.00      22.22          1\n",
    "    playlist name (label_id: 40)                             0.00       0.00       0.00          1\n",
    "    podcast descriptor (label_id: 41)                      100.00      84.62      91.67         13\n",
    "    podcast name (label_id: 42)                             33.33      25.00      28.57          4\n",
    "    radio name (label_id: 43)                               93.75      78.95      85.71         38\n",
    "    relation (label_id: 44)                                 75.00      70.59      72.73         17\n",
    "    song name (label_id: 45)                                60.00      40.91      48.65         22\n",
    "    time (label_id: 46)                                     82.48      85.61      84.01        132\n",
    "    time zone (label_id: 47)                                77.78     100.00      87.50          7\n",
    "    timeofday (label_id: 48)                                80.65      89.29      84.75         28\n",
    "    transport agency (label_id: 49)                        100.00     100.00     100.00          9\n",
    "    transport descriptor (label_id: 50)                      0.00       0.00       0.00          0\n",
    "    transport name (label_id: 51)                           80.00     100.00      88.89          4\n",
    "    transport type (label_id: 52)                           97.06      94.29      95.65         35\n",
    "    weather descriptor (label_id: 53)                       90.91      66.67      76.92         15\n",
    "    other (label_id: 54)                                    96.59      96.32      96.46       3291\n",
    "    -------------------\n",
    "    micro avg                                               92.53      92.53      92.53       4523\n",
    "    macro avg                                               76.34      77.14      74.44       4523\n",
    "    weighted avg                                            92.99      92.53      92.56       4523\n",
    "\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃           Test metric            ┃           DataLoader 0           ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│           bio_slot_f1            │        94.04096984863281         │\n",
    "│        bio_slot_precision        │        94.04096984863281         │\n",
    "│         bio_slot_recall          │        94.04096984863281         │\n",
    "│         overall_slot_f1          │        92.52709197998047         │\n",
    "│      overall_slot_precision      │        92.52708435058594         │\n",
    "│       overall_slot_recall        │        92.52708435058594         │\n",
    "│        slot_similarity_f1        │              91.875              │\n",
    "│    slot_similarity_precision     │              91.875              │\n",
    "│      slot_similarity_recall      │              91.875              │\n",
    "│         unified_slot_f1          │        80.28195816548065         │\n",
    "│ unified_slot_joint_goal_accuracy │         71.2624584717608         │\n",
    "│      unified_slot_precision      │        79.27740863787376         │\n",
    "│       unified_slot_recall        │        81.31229235880399         │\n",
    "│             val_loss             │        0.6432915925979614        │\n",
    "└──────────────────────────────────┴──────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 (Optional) Download CoNLL-2003 dataset and convert to NeMo format\n",
    "\n",
    "\n",
    "The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups.\n",
    "\n",
    "\n",
    "For more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\n",
    "\n",
    "######################################################################\n",
    "\n",
    "Licensing Information\n",
    "\n",
    "From the CoNLL2003 shared task page: https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "\n",
    "\"The English data is a collection of news wire articles from the Reuters Corpus. The annotation has been done by people of the University of Antwerp. Because of copyright reasons we only make available the annotations. In order to build the complete data sets you will need access to the Reuters Corpus. It can be obtained for research purposes without any charge from NIST.\"\n",
    "\n",
    "\n",
    "The copyrights are defined below, from the Reuters Corpus page: https://trec.nist.gov/data/reuters/reuters.html\n",
    "\n",
    "\"The stories in the Reuters Corpus are under the copyright of Reuters Ltd and/or Thomson Reuters, and their use is governed by the following agreements:\n",
    "\n",
    "Organizational agreement https://trec.nist.gov/data/reuters/org_appl_reuters_v4.html\n",
    "\n",
    "This agreement must be signed by the person responsible for the data at your organization, and sent to NIST.\n",
    "\n",
    "Individual agreement https://trec.nist.gov/data/reuters/ind_appl_reuters_v4.html\n",
    "\n",
    "This agreement must be signed by all researchers using the Reuters Corpus at your organization, and kept on file at your organization.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip the example dataset from deepai.org\n",
    "!wget https://data.deepai.org/conll2003.zip\n",
    "!unzip conll2003.zip -d ./conll_2003\n",
    "\n",
    "# convert the CoNLL-2003 IOB format (short for inside, outside, beginning) dataset to the NeMo format\n",
    "!python NeMo/examples/nlp/token_classification/data/import_from_iob_format.py --data_file=./conll_2003/train.txt\n",
    "!python NeMo/examples/nlp/token_classification/data/import_from_iob_format.py --data_file=./conll_2003/test.txt\n",
    "!python NeMo/examples/nlp/token_classification/data/import_from_iob_format.py --data_file=./conll_2003/valid.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 (Optional) Pre-process the CoNLL-2003 dataset and Generate slot class description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process dataset for zero shot slot filling\n",
    "!python NeMo/examples/nlp/dialogue/preprocess_for_zero_shot_slot_filling.py --preprocess_file_path ./conll_2003/ --dataset conll_2003\n",
    "\n",
    "# generate description of the slot class from pre-processed dataset\n",
    "!python NeMo/examples/nlp/dialogue/generate_description_for_zero_shot_slot_filling.py --preprocess_file_path ./conll_2003/with_entity/ --dataset conll_2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 (Optional) Training and/or Testing the model using CoNLL-2003 Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-19 14:01:48 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "2022-08-19 14:01:49.267748: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "[NeMo W 2022-08-19 14:01:50 nemo_logging:349] /home/lilee/python3/py38/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2022-08-19 14:01:50 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-08-19 14:01:50 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "Global seed set to 42\n",
      "[NeMo I 2022-08-19 14:01:51 dialogue:67] Config: pretrained_model: null\n",
      "    do_training: true\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 1\n",
      "      max_steps: -1\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 1.0\n",
      "      precision: 16\n",
      "      accelerator: gpu\n",
      "      log_every_n_steps: 5\n",
      "      val_check_interval: 1.0\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "    model:\n",
      "      tensor_model_parallel_size: 1\n",
      "      nemo_path: nemo_experiments/conll2003/conll2003_0.7_0.3_epoch_1_lr_0.00005.nemo\n",
      "      library: huggingface\n",
      "      save_model: false\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-base-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      tokens_to_generate: 32\n",
      "      class_balancing: ${model.dataset.class_balancing}\n",
      "      intent_loss_weight: 0.6\n",
      "      data_dir: ${model.dataset.data_dir}\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      bio_slot_loss_weight: 0.7\n",
      "      prompt_learning: false\n",
      "      language_model_path: ${model.language_model.lm_checkpoint}\n",
      "      new_tasks:\n",
      "      - intent_and_slot\n",
      "      prompt_tuning:\n",
      "        new_prompt_init_methods:\n",
      "        - text\n",
      "        new_prompt_init_text:\n",
      "        - intent classification and slot filling\n",
      "      data: {}\n",
      "      virtual_prompt_style: prompt-tuning\n",
      "      encoder_seq_length: 2048\n",
      "      pipeline_model_parallel_size: 1\n",
      "      global_batch_size: 8\n",
      "      micro_batch_size: 8\n",
      "      task_templates:\n",
      "      - taskname: intent_and_slot\n",
      "        prompt_template: \"<|VIRTUAL_PROMPT_0|> {utterance} \\nintent: {intent} \\nslot:\\\n",
      "          \\ {slot}\"\n",
      "        total_virtual_tokens: 10\n",
      "        answer_only_loss: true\n",
      "        virtual_token_splits:\n",
      "        - 10\n",
      "        truncate_field: null\n",
      "      encoder:\n",
      "        dropout: 0.1\n",
      "      original_nemo_checkpoint: null\n",
      "      dataset:\n",
      "        data_dir: ./conll_2003/with_entity\n",
      "        dialogues_example_dir: ./conll_2003/with_entity_prediction\n",
      "        task: zero_shot_slot_filling\n",
      "        debug_mode: false\n",
      "        max_seq_length: 128\n",
      "        input_field: utterance+response\n",
      "        output_field: fluent_response\n",
      "        field: intent\n",
      "        few_shot: 0\n",
      "        eval_mode: ranking\n",
      "        binary_score_subsample: false\n",
      "        binary_score_subsample_ratio: 2\n",
      "        prompt_template: default\n",
      "        target_template: default\n",
      "        system_utterance: prev_turn\n",
      "        num_tasks: 1\n",
      "        preprocess_intent_function: default\n",
      "        subsample: false\n",
      "        task_name: sgd_single_domain\n",
      "        state_tracker: nemotracker\n",
      "        use_cache: false\n",
      "        use_fuzzy_match: true\n",
      "        joint_acc_across_turn: false\n",
      "        max_num_cat_slot: 6\n",
      "        max_num_noncat_slot: 12\n",
      "        max_value_per_cat_slot: 12\n",
      "        max_num_intent: 4\n",
      "        num_samples: -1\n",
      "        pad_label: -1\n",
      "        ignore_extra_tokens: false\n",
      "        ignore_start_end: true\n",
      "        do_lowercase: false\n",
      "        class_balancing: null\n",
      "        num_classes: 3\n",
      "        dev_proportion: 10\n",
      "      train_ds:\n",
      "        ds_item: train\n",
      "        prefix: train\n",
      "        batch_size: 16\n",
      "        shuffle: true\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      validation_ds:\n",
      "        prefix: test\n",
      "        ds_item:\n",
      "        - dev\n",
      "        batch_size: 8\n",
      "        shuffle: false\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      test_ds:\n",
      "        prefix: test\n",
      "        ds_item:\n",
      "        - test\n",
      "        batch_size: 8\n",
      "        shuffle: false\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 5.0e-05\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        weight_decay: 0.01\n",
      "        sched:\n",
      "          name: PolynomialDecayAnnealing\n",
      "          warmup_steps: null\n",
      "          warmup_ratio: 0.02\n",
      "          last_epoch: -1\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: SGDGEN\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: ???\n",
      "        project: SGDGEN\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "    \n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "[NeMo I 2022-08-19 14:01:51 exp_manager:286] Experiments will be logged at /home/lilee/nemo_experiments/SGDGEN/2022-08-19_14-01-51\n",
      "[NeMo I 2022-08-19 14:01:51 exp_manager:660] TensorboardLogger has been set up\n",
      "[NeMo W 2022-08-19 14:01:51 nemo_logging:349] /home/lilee/python3/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2271: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-08-19 14:01:51 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-08-19 14:01:51 dialogue:122] Config: pretrained_model: null\n",
      "    do_training: true\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 1\n",
      "      max_steps: -1\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 1.0\n",
      "      precision: 16\n",
      "      accelerator: gpu\n",
      "      log_every_n_steps: 5\n",
      "      val_check_interval: 1.0\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "    model:\n",
      "      tensor_model_parallel_size: 1\n",
      "      nemo_path: nemo_experiments/conll2003/conll2003_0.7_0.3_epoch_1_lr_0.00005.nemo\n",
      "      library: huggingface\n",
      "      save_model: false\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-base-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      tokens_to_generate: 32\n",
      "      class_balancing: ${model.dataset.class_balancing}\n",
      "      intent_loss_weight: 0.6\n",
      "      data_dir: ${model.dataset.data_dir}\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      bio_slot_loss_weight: 0.7\n",
      "      prompt_learning: false\n",
      "      language_model_path: ${model.language_model.lm_checkpoint}\n",
      "      new_tasks:\n",
      "      - intent_and_slot\n",
      "      prompt_tuning:\n",
      "        new_prompt_init_methods:\n",
      "        - text\n",
      "        new_prompt_init_text:\n",
      "        - intent classification and slot filling\n",
      "      data: {}\n",
      "      virtual_prompt_style: prompt-tuning\n",
      "      encoder_seq_length: 2048\n",
      "      pipeline_model_parallel_size: 1\n",
      "      global_batch_size: 8\n",
      "      micro_batch_size: 8\n",
      "      task_templates:\n",
      "      - taskname: intent_and_slot\n",
      "        prompt_template: \"<|VIRTUAL_PROMPT_0|> {utterance} \\nintent: {intent} \\nslot:\\\n",
      "          \\ {slot}\"\n",
      "        total_virtual_tokens: 10\n",
      "        answer_only_loss: true\n",
      "        virtual_token_splits:\n",
      "        - 10\n",
      "        truncate_field: null\n",
      "      encoder:\n",
      "        dropout: 0.1\n",
      "      original_nemo_checkpoint: null\n",
      "      dataset:\n",
      "        data_dir: ./conll_2003/with_entity\n",
      "        dialogues_example_dir: ./conll_2003/with_entity_prediction\n",
      "        task: zero_shot_slot_filling\n",
      "        debug_mode: false\n",
      "        max_seq_length: 128\n",
      "        input_field: utterance+response\n",
      "        output_field: fluent_response\n",
      "        field: intent\n",
      "        few_shot: 0\n",
      "        eval_mode: ranking\n",
      "        binary_score_subsample: false\n",
      "        binary_score_subsample_ratio: 2\n",
      "        prompt_template: default\n",
      "        target_template: default\n",
      "        system_utterance: prev_turn\n",
      "        num_tasks: 1\n",
      "        preprocess_intent_function: default\n",
      "        subsample: false\n",
      "        task_name: sgd_single_domain\n",
      "        state_tracker: nemotracker\n",
      "        use_cache: false\n",
      "        use_fuzzy_match: true\n",
      "        joint_acc_across_turn: false\n",
      "        max_num_cat_slot: 6\n",
      "        max_num_noncat_slot: 12\n",
      "        max_value_per_cat_slot: 12\n",
      "        max_num_intent: 4\n",
      "        num_samples: -1\n",
      "        pad_label: -1\n",
      "        ignore_extra_tokens: false\n",
      "        ignore_start_end: true\n",
      "        do_lowercase: false\n",
      "        class_balancing: null\n",
      "        num_classes: 3\n",
      "        dev_proportion: 10\n",
      "      train_ds:\n",
      "        ds_item: train\n",
      "        prefix: train\n",
      "        batch_size: 16\n",
      "        shuffle: true\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      validation_ds:\n",
      "        prefix: test\n",
      "        ds_item:\n",
      "        - dev\n",
      "        batch_size: 8\n",
      "        shuffle: false\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      test_ds:\n",
      "        prefix: test\n",
      "        ds_item:\n",
      "        - test\n",
      "        batch_size: 8\n",
      "        shuffle: false\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 5.0e-05\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        weight_decay: 0.01\n",
      "        sched:\n",
      "          name: PolynomialDecayAnnealing\n",
      "          warmup_steps: null\n",
      "          warmup_ratio: 0.02\n",
      "          last_epoch: -1\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: SGDGEN\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: ???\n",
      "        project: SGDGEN\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "    \n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:87]  Stats calculating for train mode...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:112] Three most popular intents in train mode:\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 0, 11132 out of 11132 (100.00%).\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:118] Three most popular slots in train mode:\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 0, 124517 out of 158493 (78.56%).\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 1, 7140 out of 158493 (4.50%).\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 7, 6600 out of 158493 (4.16%).\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:121] Total Number of Intents: 11132\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:122] Intent Label Frequencies: {0: 11132}\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:123] Total Number of Slots: 158493\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:124] Slots Label Frequencies: {0: 124517, 1: 7140, 7: 6600, 5: 6320, 8: 4528, 6: 3652, 3: 3438, 4: 1150, 2: 1148}\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:128] Intent Weights: {0: 1.0}\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:130] Slot Weights: {0: 0.14142914889800856, 1: 2.466433239962652, 7: 2.6682323232323233, 5: 2.786445147679325, 8: 3.8892078916372204, 6: 4.822106608251187, 3: 5.122261004459958, 4: 15.313333333333333, 2: 15.340011614401858}\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:87]  Stats calculating for test mode...\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:112] Three most popular intents in test mode:\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 0, 2756 out of 2756 (100.00%).\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:118] Three most popular slots in test mode:\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 0, 28424 out of 36531 (77.81%).\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 1, 1668 out of 36531 (4.57%).\n",
      "[NeMo I 2022-08-19 14:01:51 data_preprocessing:194] label: 5, 1661 out of 36531 (4.55%).\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:121] Total Number of Intents: 2756\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:122] Intent Label Frequencies: {0: 2756}\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:123] Total Number of Slots: 36531\n",
      "[NeMo I 2022-08-19 14:01:51 intent_slot_classification_descriptor:124] Slots Label Frequencies: {0: 28424, 1: 1668, 5: 1661, 7: 1617, 8: 1156, 6: 831, 3: 702, 2: 257, 4: 215}\n",
      "[NeMo I 2022-08-19 14:01:51 dialogue_zero_shot_slot_filling_model:138] Labels: {'O': 0, 'B-LOC': 1, 'I-LOC': 2, 'B-MISC': 3, 'I-MISC': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-PER': 7, 'I-PER': 8}\n",
      "[NeMo I 2022-08-19 14:01:51 dialogue_zero_shot_slot_filling_model:139] Labels mapping saved to : ./conll_2003/with_entity/slot_labels.csv\n",
      "[NeMo I 2022-08-19 14:01:51 dialogue_zero_shot_slot_filling_model:138] Labels: {'same': 0}\n",
      "[NeMo I 2022-08-19 14:01:51 dialogue_zero_shot_slot_filling_model:139] Labels mapping saved to : ./conll_2003/with_entity/intent_labels.csv\n",
      "[NeMo I 2022-08-19 14:01:51 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: None, merges_files: None, special_tokens_dict: {}, and use_fast: False\n",
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-08-19 14:01:54 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Created a temporary directory at /tmp/tmpewyznbok\n",
      "Writing /tmp/tmpewyznbok/_remote_module_non_sriptable.py\n",
      "[NeMo I 2022-08-19 14:01:59 dialogue_zero_shot_slot_filling_dataset:329] Setting max length to: 128\n",
      "[NeMo I 2022-08-19 14:01:59 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-19 14:01:59 data_preprocessing:406] Min: 3 |                  Max: 164 |                  Mean: 21.276103014573767 |                  Median: 17.0\n",
      "[NeMo I 2022-08-19 14:01:59 data_preprocessing:412] 75 percentile: 31.00\n",
      "[NeMo I 2022-08-19 14:01:59 data_preprocessing:413] 99 percentile: 57.00\n",
      "[NeMo I 2022-08-19 14:02:00 dialogue_zero_shot_slot_filling_dataset:254] 1 are longer than 128\n",
      "[NeMo I 2022-08-19 14:02:01 dialogue_zero_shot_slot_filling_dataset:329] Setting max length to: 77\n",
      "[NeMo I 2022-08-19 14:02:01 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-19 14:02:01 data_preprocessing:406] Min: 3 |                  Max: 77 |                  Mean: 20.689407540394974 |                  Median: 16.0\n",
      "[NeMo I 2022-08-19 14:02:01 data_preprocessing:412] 75 percentile: 30.00\n",
      "[NeMo I 2022-08-19 14:02:01 data_preprocessing:413] 99 percentile: 56.87\n",
      "[NeMo I 2022-08-19 14:02:01 dialogue_zero_shot_slot_filling_dataset:254] 0 are longer than 77\n",
      "[NeMo I 2022-08-19 14:02:02 dialogue_zero_shot_slot_filling_dataset:329] Setting max length to: 128\n",
      "[NeMo I 2022-08-19 14:02:02 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-19 14:02:02 data_preprocessing:406] Min: 3 |                  Max: 140 |                  Mean: 19.767416545718433 |                  Median: 14.0\n",
      "[NeMo I 2022-08-19 14:02:02 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2022-08-19 14:02:02 data_preprocessing:413] 99 percentile: 60.00\n",
      "[NeMo I 2022-08-19 14:02:02 dialogue_zero_shot_slot_filling_dataset:254] 1 are longer than 128\n",
      "[NeMo W 2022-08-19 14:02:02 nlp_overrides:228] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-19 14:02:08 nemo_logging:349] /home/lilee/python3/py38/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (ClassificationReport). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "[NeMo I 2022-08-19 14:02:11 modelPT:597] Optimizer config = AdamW (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.9, 0.999]\n",
      "        eps: 1e-08\n",
      "        lr: 5e-05\n",
      "        maximize: False\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2022-08-19 14:02:11 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.PolynomialDecayAnnealing object at 0x7f91a573de80>\" \n",
      "    will be used during training (effective maximum steps = 627) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.02\n",
      "    last_epoch: -1\n",
      "    max_steps: 627\n",
      "    )\n",
      "\n",
      "  | Name                                  | Type                 | Params\n",
      "-------------------------------------------------------------------------------\n",
      "0 | bert_model                            | BertEncoder          | 109 M \n",
      "1 | bio_mlp                               | MultiLayerPerceptron | 592 K \n",
      "2 | mention_projection_mlp                | Linear               | 230 K \n",
      "3 | description_projection_mlp            | Linear               | 230 K \n",
      "4 | bio_slot_loss                         | CrossEntropyLoss     | 0     \n",
      "5 | slot_loss                             | CrossEntropyLoss     | 0     \n",
      "6 | total_loss                            | AggregatorLoss       | 0     \n",
      "7 | bio_slot_classification_report        | ClassificationReport | 0     \n",
      "8 | slot_similarity_classification_report | ClassificationReport | 0     \n",
      "9 | overall_slot_classification_report    | ClassificationReport | 0     \n",
      "-------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "221.072   Total estimated model params size (MB)\n",
      "Epoch 0:  82%|▊| 627/767 [03:13<00:43,  3.25it/s, loss=0.0734, v_num=1-51, lr=8.\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                       | 0/140 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                          | 0/140 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  82%|▊| 628/767 [03:13<00:42,  3.25it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  82%|▊| 629/767 [03:13<00:42,  3.25it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  82%|▊| 630/767 [03:13<00:42,  3.25it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  82%|▊| 631/767 [03:13<00:41,  3.26it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  82%|▊| 632/767 [03:13<00:41,  3.26it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 633/767 [03:13<00:41,  3.26it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 634/767 [03:14<00:40,  3.27it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 635/767 [03:14<00:40,  3.27it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 636/767 [03:14<00:40,  3.27it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 637/767 [03:14<00:39,  3.28it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 638/767 [03:14<00:39,  3.28it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 639/767 [03:14<00:38,  3.28it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  83%|▊| 640/767 [03:14<00:38,  3.28it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 641/767 [03:14<00:38,  3.29it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 642/767 [03:15<00:37,  3.29it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 643/767 [03:15<00:37,  3.29it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 644/767 [03:15<00:37,  3.30it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 645/767 [03:15<00:36,  3.30it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 646/767 [03:15<00:36,  3.30it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 647/767 [03:15<00:36,  3.31it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  84%|▊| 648/767 [03:15<00:35,  3.31it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 649/767 [03:15<00:35,  3.31it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 650/767 [03:16<00:35,  3.32it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 651/767 [03:16<00:34,  3.32it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 652/767 [03:16<00:34,  3.32it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 653/767 [03:16<00:34,  3.32it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 654/767 [03:16<00:33,  3.33it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  85%|▊| 655/767 [03:16<00:33,  3.33it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 656/767 [03:16<00:33,  3.33it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 657/767 [03:16<00:32,  3.34it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 658/767 [03:17<00:32,  3.34it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 659/767 [03:17<00:32,  3.34it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 660/767 [03:17<00:31,  3.35it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 661/767 [03:17<00:31,  3.35it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 662/767 [03:17<00:31,  3.35it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  86%|▊| 663/767 [03:17<00:30,  3.36it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 664/767 [03:17<00:30,  3.36it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 665/767 [03:17<00:30,  3.36it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 666/767 [03:17<00:30,  3.36it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 667/767 [03:18<00:29,  3.37it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 668/767 [03:18<00:29,  3.37it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 669/767 [03:18<00:29,  3.37it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 670/767 [03:18<00:28,  3.38it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  87%|▊| 671/767 [03:18<00:28,  3.38it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 672/767 [03:18<00:28,  3.38it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 673/767 [03:18<00:27,  3.39it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 674/767 [03:18<00:27,  3.39it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 675/767 [03:19<00:27,  3.39it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 676/767 [03:19<00:26,  3.39it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 677/767 [03:19<00:26,  3.40it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  88%|▉| 678/767 [03:19<00:26,  3.40it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 679/767 [03:19<00:25,  3.40it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 680/767 [03:19<00:25,  3.41it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 681/767 [03:19<00:25,  3.41it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 682/767 [03:19<00:24,  3.41it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 683/767 [03:19<00:24,  3.42it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 684/767 [03:20<00:24,  3.42it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 685/767 [03:20<00:23,  3.42it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  89%|▉| 686/767 [03:20<00:23,  3.43it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 687/767 [03:20<00:23,  3.43it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 688/767 [03:20<00:23,  3.43it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 689/767 [03:20<00:22,  3.43it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  90%|▉| 690/767 [03:20<00:22,  3.44it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 691/767 [03:20<00:22,  3.44it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 692/767 [03:20<00:21,  3.44it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 693/767 [03:21<00:21,  3.45it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  90%|▉| 694/767 [03:21<00:21,  3.45it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 695/767 [03:21<00:20,  3.45it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 696/767 [03:21<00:20,  3.45it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 697/767 [03:21<00:20,  3.46it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 698/767 [03:21<00:19,  3.46it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 699/767 [03:21<00:19,  3.46it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 700/767 [03:21<00:19,  3.47it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  91%|▉| 701/767 [03:22<00:19,  3.47it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 702/767 [03:22<00:18,  3.47it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 703/767 [03:22<00:18,  3.47it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 704/767 [03:22<00:18,  3.48it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 705/767 [03:22<00:17,  3.48it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 706/767 [03:22<00:17,  3.48it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 707/767 [03:22<00:17,  3.49it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 708/767 [03:22<00:16,  3.49it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  92%|▉| 709/767 [03:22<00:16,  3.49it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 710/767 [03:23<00:16,  3.50it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 711/767 [03:23<00:16,  3.50it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 712/767 [03:23<00:15,  3.50it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 713/767 [03:23<00:15,  3.50it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 714/767 [03:23<00:15,  3.51it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 715/767 [03:23<00:14,  3.51it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 716/767 [03:23<00:14,  3.51it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  93%|▉| 717/767 [03:23<00:14,  3.52it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 718/767 [03:23<00:13,  3.52it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 719/767 [03:24<00:13,  3.52it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 720/767 [03:24<00:13,  3.53it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 721/767 [03:24<00:13,  3.53it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 722/767 [03:24<00:12,  3.53it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 723/767 [03:24<00:12,  3.53it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  94%|▉| 724/767 [03:24<00:12,  3.54it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 725/767 [03:24<00:11,  3.54it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 726/767 [03:24<00:11,  3.54it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 727/767 [03:25<00:11,  3.55it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 728/767 [03:25<00:10,  3.55it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 729/767 [03:25<00:10,  3.55it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 730/767 [03:25<00:10,  3.55it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 731/767 [03:25<00:10,  3.56it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  95%|▉| 732/767 [03:25<00:09,  3.56it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 733/767 [03:25<00:09,  3.56it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 734/767 [03:25<00:09,  3.57it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 735/767 [03:25<00:08,  3.57it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 736/767 [03:26<00:08,  3.57it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 737/767 [03:26<00:08,  3.57it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 738/767 [03:26<00:08,  3.58it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 739/767 [03:26<00:07,  3.58it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  96%|▉| 740/767 [03:26<00:07,  3.58it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 741/767 [03:26<00:07,  3.59it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 742/767 [03:26<00:06,  3.59it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 743/767 [03:26<00:06,  3.59it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 744/767 [03:26<00:06,  3.59it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 745/767 [03:27<00:06,  3.60it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 746/767 [03:27<00:05,  3.60it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  97%|▉| 747/767 [03:27<00:05,  3.60it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 748/767 [03:27<00:05,  3.61it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 749/767 [03:27<00:04,  3.61it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 750/767 [03:27<00:04,  3.61it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 751/767 [03:27<00:04,  3.61it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 752/767 [03:27<00:04,  3.62it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 753/767 [03:28<00:03,  3.62it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 754/767 [03:28<00:03,  3.62it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  98%|▉| 755/767 [03:28<00:03,  3.63it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 756/767 [03:28<00:03,  3.63it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 757/767 [03:28<00:02,  3.63it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 758/767 [03:28<00:02,  3.63it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 759/767 [03:28<00:02,  3.64it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 760/767 [03:28<00:01,  3.64it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 761/767 [03:28<00:01,  3.64it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 762/767 [03:29<00:01,  3.64it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0:  99%|▉| 763/767 [03:29<00:01,  3.65it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0: 100%|▉| 764/767 [03:29<00:00,  3.65it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0: 100%|▉| 765/767 [03:29<00:00,  3.65it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0: 100%|▉| 766/767 [03:29<00:00,  3.66it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A\n",
      "Epoch 0: 100%|█| 767/767 [03:29<00:00,  3.66it/s, loss=0.0734, v_num=1-51, lr=8.\u001b[A[NeMo I 2022-08-19 14:05:45 dialogue_zero_shot_slot_filling_model:649] BIO slot report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    0 (label_id: 0)                                         98.64      98.23      98.43      16548\n",
      "    1 (label_id: 1)                                         93.29      94.40      93.84       1679\n",
      "    2 (label_id: 2)                                         92.24      93.98      93.10       2593\n",
      "    -------------------\n",
      "    micro avg                                               97.39      97.39      97.39      20820\n",
      "    macro avg                                               94.72      95.54      95.13      20820\n",
      "    weighted avg                                            97.41      97.39      97.40      20820\n",
      "    \n",
      "[NeMo I 2022-08-19 14:05:45 dialogue_zero_shot_slot_filling_model:657] Slot similarity report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    other (label_id: 0)                                      0.00       0.00       0.00          0\n",
      "    location (label_id: 1)                                  95.81      98.05      96.92        513\n",
      "    miscellaneous (label_id: 2)                             95.91      94.51      95.20        273\n",
      "    organization (label_id: 3)                              94.68      96.11      95.39        463\n",
      "    person (label_id: 4)                                    99.28      95.81      97.51        430\n",
      "    -------------------\n",
      "    micro avg                                               96.37      96.37      96.37       1679\n",
      "    macro avg                                               96.42      96.12      96.26       1679\n",
      "    weighted avg                                            96.40      96.37      96.37       1679\n",
      "    \n",
      "[NeMo I 2022-08-19 14:05:45 dialogue_zero_shot_slot_filling_model:665] Overall slot report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    other (label_id: 0)                                     98.55      98.81      98.68      12924\n",
      "    location (label_id: 1)                                  80.14      89.40      84.52        632\n",
      "    miscellaneous (label_id: 2)                             83.04      77.17      80.00        368\n",
      "    organization (label_id: 3)                              85.65      80.42      82.95        720\n",
      "    person (label_id: 4)                                    96.73      92.08      94.34        770\n",
      "    -------------------\n",
      "    micro avg                                               96.71      96.71      96.71      15414\n",
      "    macro avg                                               88.82      87.58      88.10      15414\n",
      "    weighted avg                                            96.73      96.71      96.70      15414\n",
      "    \n",
      "Epoch 0: 100%|█| 767/767 [03:33<00:00,  3.59it/s, loss=0.0734, v_num=1-51, lr=8.\n",
      "Epoch 0: 100%|█| 767/767 [03:33<00:00,  3.59it/s, loss=0.0734, v_num=1-51, lr=8.Epoch 0, global step 627: 'val_loss' reached 0.08086 (best 0.08086), saving model to '/home/lilee/nemo_experiments/SGDGEN/2022-08-19_14-01-51/checkpoints/SGDGEN--val_loss=0.0809-epoch=0.ckpt' as top 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|█| 767/767 [03:37<00:00,  3.52it/s, loss=0.0734, v_num=1-51, lr=8.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-08-19 14:05:55 dialogue_zero_shot_slot_filling_dataset:329] Setting max length to: 128\n",
      "[NeMo I 2022-08-19 14:05:55 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-19 14:05:55 data_preprocessing:406] Min: 3 |                  Max: 140 |                  Mean: 19.767416545718433 |                  Median: 14.0\n",
      "[NeMo I 2022-08-19 14:05:55 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2022-08-19 14:05:55 data_preprocessing:413] 99 percentile: 60.00\n",
      "[NeMo I 2022-08-19 14:05:55 dialogue_zero_shot_slot_filling_dataset:254] 1 are longer than 128\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Testing DataLoader 0: 100%|███████████████████| 345/345 [00:59<00:00,  5.84it/s][NeMo I 2022-08-19 14:07:11 dialogue_zero_shot_slot_filling_model:649] BIO slot report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    0 (label_id: 0)                                         98.80      97.89      98.34      38900\n",
      "    1 (label_id: 1)                                         92.51      93.85      93.18       4082\n",
      "    2 (label_id: 2)                                         90.54      95.03      92.73       5973\n",
      "    -------------------\n",
      "    micro avg                                               97.21      97.21      97.21      48955\n",
      "    macro avg                                               93.95      95.59      94.75      48955\n",
      "    weighted avg                                            97.27      97.21      97.23      48955\n",
      "    \n",
      "[NeMo I 2022-08-19 14:07:11 dialogue_zero_shot_slot_filling_model:657] Slot similarity report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    other (label_id: 0)                                      0.00       0.00       0.00          0\n",
      "    location (label_id: 1)                                  93.54      96.05      94.78       1266\n",
      "    miscellaneous (label_id: 2)                             89.77      90.41      90.09        563\n",
      "    organization (label_id: 3)                              92.43      91.45      91.94       1228\n",
      "    person (label_id: 4)                                    99.00      96.59      97.78       1025\n",
      "    -------------------\n",
      "    micro avg                                               94.02      94.02      94.02       4082\n",
      "    macro avg                                               93.68      93.62      93.65       4082\n",
      "    weighted avg                                            94.06      94.02      94.03       4082\n",
      "    \n",
      "[NeMo I 2022-08-19 14:07:11 dialogue_zero_shot_slot_filling_model:665] Overall slot report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    other (label_id: 0)                                     98.74      98.58      98.66      30551\n",
      "    location (label_id: 1)                                  76.88      90.61      83.18       1523\n",
      "    miscellaneous (label_id: 2)                             77.34      72.99      75.10        748\n",
      "    organization (label_id: 3)                              84.72      78.04      81.24       1826\n",
      "    person (label_id: 4)                                    95.38      93.60      94.48       1874\n",
      "    -------------------\n",
      "    micro avg                                               96.44      96.44      96.44      36522\n",
      "    macro avg                                               86.61      86.76      86.53      36522\n",
      "    weighted avg                                            96.52      96.44      96.45      36522\n",
      "    \n",
      "Testing DataLoader 0: 100%|███████████████████| 345/345 [01:15<00:00,  4.57it/s]\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│\u001b[36m \u001b[0m\u001b[36m          bio_slot_f1           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       97.20763397216797        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m       bio_slot_precision       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        97.2076416015625        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m        bio_slot_recall         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m        97.2076416015625        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m        overall_slot_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       96.44049835205078        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m     overall_slot_precision     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       96.44049835205078        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m      overall_slot_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       96.44049835205078        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m       slot_similarity_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       94.02253723144531        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m   slot_similarity_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       94.02253723144531        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m     slot_similarity_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       94.02253723144531        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m        unified_slot_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       81.62207207376734        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36munified_slot_joint_goal_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       74.56458635703919        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m     unified_slot_precision     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       82.10873246250604        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m      unified_slot_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       81.14114658925979        \u001b[0m\u001b[35m \u001b[0m│\n",
      "│\u001b[36m \u001b[0m\u001b[36m            val_loss            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.1337154656648636       \u001b[0m\u001b[35m \u001b[0m│\n",
      "└──────────────────────────────────┴──────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "# trainer.max_epochs: number of epochs for training\n",
    "# model.bio_slot_loss_weight: mention detection (BIO tagging) loss weight\n",
    "# model.nemo_path: the path that stores trained nemo model\n",
    "# model.optim.lr: learning rate for trianing\n",
    "# fine-tuned best overall f1 score in CoNLL-2003 dataset at parameter: bio_slot_loss_weight=0.7, max_epochs=5, optim.lr=0.00005\n",
    "\n",
    "  \n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=True \\\n",
    "  model.dataset.data_dir=\"./conll_2003/with_entity\" \\\n",
    "  model.dataset.dialogues_example_dir=\"./conll_2003/with_entity_prediction\" \\\n",
    "  model.dataset.task='zero_shot_slot_filling' \\\n",
    "  model.language_model.pretrained_model_name='bert-base-uncased' \\\n",
    "  exp_manager.create_wandb_logger=False \\\n",
    "  trainer.max_epochs=1 \\\n",
    "  model.bio_slot_loss_weight=0.7 \\\n",
    "  model.nemo_path=\"nemo_experiments/conll2003/conll2003_0.7_0.3_epoch_1_lr_0.00005.nemo\" \\\n",
    "  model.optim.lr=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After 1 epoch:**\n",
    "\n",
    "Fine-tuned with bio_slot_loss_weight=0.7, max_epochs=5, optim.lr=0.00005 get best overall f1 score\n",
    "\n",
    "BIO slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    0 (label_id: 0)                                         98.80      97.89      98.34      38900\n",
    "    1 (label_id: 1)                                         92.51      93.85      93.18       4082\n",
    "    2 (label_id: 2)                                         90.54      95.03      92.73       5973\n",
    "    -------------------\n",
    "    micro avg                                               97.21      97.21      97.21      48955\n",
    "    macro avg                                               93.95      95.59      94.75      48955\n",
    "    weighted avg                                            97.27      97.21      97.23      48955\n",
    "```\n",
    "Slot similarity report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    other (label_id: 0)                                      0.00       0.00       0.00          0\n",
    "    location (label_id: 1)                                  93.54      96.05      94.78       1266\n",
    "    miscellaneous (label_id: 2)                             89.77      90.41      90.09        563\n",
    "    organization (label_id: 3)                              92.43      91.45      91.94       1228\n",
    "    person (label_id: 4)                                    99.00      96.59      97.78       1025\n",
    "    -------------------\n",
    "    micro avg                                               94.02      94.02      94.02       4082\n",
    "    macro avg                                               93.68      93.62      93.65       4082\n",
    "    weighted avg                                            94.06      94.02      94.03       4082\n",
    "```\n",
    "\n",
    "Overall slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    other (label_id: 0)                                     98.74      98.58      98.66      30551\n",
    "    location (label_id: 1)                                  76.88      90.61      83.18       1523\n",
    "    miscellaneous (label_id: 2)                             77.34      72.99      75.10        748\n",
    "    organization (label_id: 3)                              84.72      78.04      81.24       1826\n",
    "    person (label_id: 4)                                    95.38      93.60      94.48       1874\n",
    "    -------------------\n",
    "    micro avg                                               96.44      96.44      96.44      36522\n",
    "    macro avg                                               86.61      86.76      86.53      36522\n",
    "    weighted avg                                            96.52      96.44      96.45      36522\n",
    "\n",
    "```\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃           Test metric            ┃           DataLoader 0           ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│           bio_slot_f1            │        97.20763397216797         │\n",
    "│        bio_slot_precision        │         97.2076416015625         │\n",
    "│         bio_slot_recall          │         97.2076416015625         │\n",
    "│         overall_slot_f1          │        96.44049835205078         │\n",
    "│      overall_slot_precision      │        96.44049835205078         │\n",
    "│       overall_slot_recall        │        96.44049835205078         │\n",
    "│        slot_similarity_f1        │        94.02253723144531         │\n",
    "│    slot_similarity_precision     │        94.02253723144531         │\n",
    "│      slot_similarity_recall      │        94.02253723144531         │\n",
    "│         unified_slot_f1          │        81.62207207376734         │\n",
    "│ unified_slot_joint_goal_accuracy │        74.56458635703919         │\n",
    "│      unified_slot_precision      │        82.10873246250604         │\n",
    "│       unified_slot_recall        │        81.14114658925979         │\n",
    "│             val_loss             │        0.1337154656648636        │\n",
    "└──────────────────────────────────┴──────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 (Optional) Testing the model out of domain\n",
    "\n",
    "Testing the Zero Shot Slot Filling Modle on CoNLL-2003 Dataset, with pre-trained model that fine-tuned on Assistant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-08-19 14:12:18 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "2022-08-19 14:12:19.788713: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "[NeMo W 2022-08-19 14:12:21 nemo_logging:349] /home/lilee/python3/py38/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2022-08-19 14:12:21 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-08-19 14:12:21 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "Global seed set to 42\n",
      "[NeMo I 2022-08-19 14:12:21 dialogue:67] Config: pretrained_model: null\n",
      "    do_training: false\n",
      "    trainer:\n",
      "      devices: 1\n",
      "      num_nodes: 1\n",
      "      max_epochs: 3\n",
      "      max_steps: -1\n",
      "      accumulate_grad_batches: 1\n",
      "      gradient_clip_val: 1.0\n",
      "      precision: 16\n",
      "      accelerator: gpu\n",
      "      log_every_n_steps: 5\n",
      "      val_check_interval: 1.0\n",
      "      resume_from_checkpoint: null\n",
      "      num_sanity_val_steps: 0\n",
      "      enable_checkpointing: false\n",
      "      logger: false\n",
      "    model:\n",
      "      tensor_model_parallel_size: 1\n",
      "      nemo_path: nemo_experiments/assistant/assistant_0.5_0.5_epoch_10_lr_0.00001.nemo\n",
      "      library: huggingface\n",
      "      save_model: false\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-base-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      tokens_to_generate: 32\n",
      "      class_balancing: ${model.dataset.class_balancing}\n",
      "      intent_loss_weight: 0.6\n",
      "      data_dir: ${model.dataset.data_dir}\n",
      "      classifier_head:\n",
      "        num_output_layers: 2\n",
      "        fc_dropout: 0.1\n",
      "      bio_slot_loss_weight: 0.5\n",
      "      prompt_learning: false\n",
      "      language_model_path: ${model.language_model.lm_checkpoint}\n",
      "      new_tasks:\n",
      "      - intent_and_slot\n",
      "      prompt_tuning:\n",
      "        new_prompt_init_methods:\n",
      "        - text\n",
      "        new_prompt_init_text:\n",
      "        - intent classification and slot filling\n",
      "      data: {}\n",
      "      virtual_prompt_style: prompt-tuning\n",
      "      encoder_seq_length: 2048\n",
      "      pipeline_model_parallel_size: 1\n",
      "      global_batch_size: 8\n",
      "      micro_batch_size: 8\n",
      "      task_templates:\n",
      "      - taskname: intent_and_slot\n",
      "        prompt_template: \"<|VIRTUAL_PROMPT_0|> {utterance} \\nintent: {intent} \\nslot:\\\n",
      "          \\ {slot}\"\n",
      "        total_virtual_tokens: 10\n",
      "        answer_only_loss: true\n",
      "        virtual_token_splits:\n",
      "        - 10\n",
      "        truncate_field: null\n",
      "      encoder:\n",
      "        dropout: 0.1\n",
      "      original_nemo_checkpoint: null\n",
      "      dataset:\n",
      "        data_dir: ./conll_2003/with_entity\n",
      "        dialogues_example_dir: ./train_assistant_test_conll2003/with_entity_prediction\n",
      "        task: zero_shot_slot_filling\n",
      "        debug_mode: false\n",
      "        max_seq_length: 128\n",
      "        input_field: utterance+response\n",
      "        output_field: fluent_response\n",
      "        field: intent\n",
      "        few_shot: 0\n",
      "        eval_mode: ranking\n",
      "        binary_score_subsample: false\n",
      "        binary_score_subsample_ratio: 2\n",
      "        prompt_template: default\n",
      "        target_template: default\n",
      "        system_utterance: prev_turn\n",
      "        num_tasks: 1\n",
      "        preprocess_intent_function: default\n",
      "        subsample: false\n",
      "        task_name: sgd_single_domain\n",
      "        state_tracker: nemotracker\n",
      "        use_cache: false\n",
      "        use_fuzzy_match: true\n",
      "        joint_acc_across_turn: false\n",
      "        max_num_cat_slot: 6\n",
      "        max_num_noncat_slot: 12\n",
      "        max_value_per_cat_slot: 12\n",
      "        max_num_intent: 4\n",
      "        num_samples: -1\n",
      "        pad_label: -1\n",
      "        ignore_extra_tokens: false\n",
      "        ignore_start_end: true\n",
      "        do_lowercase: false\n",
      "        class_balancing: null\n",
      "        num_classes: 3\n",
      "        dev_proportion: 10\n",
      "      train_ds:\n",
      "        ds_item: train\n",
      "        prefix: train\n",
      "        batch_size: 16\n",
      "        shuffle: true\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      validation_ds:\n",
      "        prefix: test\n",
      "        ds_item:\n",
      "        - dev\n",
      "        batch_size: 8\n",
      "        shuffle: false\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      test_ds:\n",
      "        prefix: test\n",
      "        ds_item:\n",
      "        - test\n",
      "        batch_size: 8\n",
      "        shuffle: false\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "      optim:\n",
      "        name: adamw\n",
      "        lr: 0.0001\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        weight_decay: 0.01\n",
      "        sched:\n",
      "          name: PolynomialDecayAnnealing\n",
      "          warmup_steps: null\n",
      "          warmup_ratio: 0.02\n",
      "          last_epoch: -1\n",
      "          monitor: val_loss\n",
      "          reduce_on_plateau: false\n",
      "    exp_manager:\n",
      "      exp_dir: null\n",
      "      name: SGDGEN\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs:\n",
      "        name: ???\n",
      "        project: SGDGEN\n",
      "      create_tensorboard_logger: true\n",
      "      create_checkpoint_callback: true\n",
      "      resume_if_exists: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "    \n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "[NeMo I 2022-08-19 14:12:22 exp_manager:286] Experiments will be logged at /home/lilee/nemo_experiments/SGDGEN/2022-08-19_14-12-22\n",
      "[NeMo I 2022-08-19 14:12:22 exp_manager:660] TensorboardLogger has been set up\n",
      "[NeMo W 2022-08-19 14:12:22 nemo_logging:349] /home/lilee/python3/py38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2271: LightningDeprecationWarning: `Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\n",
      "      rank_zero_deprecation(\"`Trainer.weights_save_path` has been deprecated in v1.6 and will be removed in v1.8.\")\n",
      "    \n",
      "[NeMo W 2022-08-19 14:12:22 exp_manager:899] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-08-19 14:12:22 dialogue:115] Restoring model from nemo_experiments/assistant/assistant_0.5_0.5_epoch_10_lr_0.00001.nemo\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:87]  Stats calculating for train mode...\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:112] Three most popular intents in train mode:\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 0, 11132 out of 11132 (100.00%).\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:118] Three most popular slots in train mode:\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 0, 124517 out of 158493 (78.56%).\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 1, 7140 out of 158493 (4.50%).\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 7, 6600 out of 158493 (4.16%).\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:121] Total Number of Intents: 11132\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:122] Intent Label Frequencies: {0: 11132}\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:123] Total Number of Slots: 158493\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:124] Slots Label Frequencies: {0: 124517, 1: 7140, 7: 6600, 5: 6320, 8: 4528, 6: 3652, 3: 3438, 4: 1150, 2: 1148}\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:128] Intent Weights: {0: 1.0}\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:130] Slot Weights: {0: 0.14142914889800856, 1: 2.466433239962652, 7: 2.6682323232323233, 5: 2.786445147679325, 8: 3.8892078916372204, 6: 4.822106608251187, 3: 5.122261004459958, 4: 15.313333333333333, 2: 15.340011614401858}\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:87]  Stats calculating for test mode...\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:112] Three most popular intents in test mode:\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 0, 2756 out of 2756 (100.00%).\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:118] Three most popular slots in test mode:\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 0, 28424 out of 36531 (77.81%).\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 1, 1668 out of 36531 (4.57%).\n",
      "[NeMo I 2022-08-19 14:12:22 data_preprocessing:194] label: 5, 1661 out of 36531 (4.55%).\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:121] Total Number of Intents: 2756\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:122] Intent Label Frequencies: {0: 2756}\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:123] Total Number of Slots: 36531\n",
      "[NeMo I 2022-08-19 14:12:22 intent_slot_classification_descriptor:124] Slots Label Frequencies: {0: 28424, 1: 1668, 5: 1661, 7: 1617, 8: 1156, 6: 831, 3: 702, 2: 257, 4: 215}\n",
      "[NeMo I 2022-08-19 14:12:22 dialogue_zero_shot_slot_filling_model:138] Labels: {'O': 0, 'B-LOC': 1, 'I-LOC': 2, 'B-MISC': 3, 'I-MISC': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-PER': 7, 'I-PER': 8}\n",
      "[NeMo I 2022-08-19 14:12:22 dialogue_zero_shot_slot_filling_model:139] Labels mapping saved to : ./conll_2003/with_entity/slot_labels.csv\n",
      "[NeMo I 2022-08-19 14:12:22 dialogue_zero_shot_slot_filling_model:138] Labels: {'same': 0}\n",
      "[NeMo I 2022-08-19 14:12:22 dialogue_zero_shot_slot_filling_model:139] Labels mapping saved to : ./conll_2003/with_entity/intent_labels.csv\n",
      "[NeMo I 2022-08-19 14:12:22 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: None, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-08-19 14:12:25 modelPT:217] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "Created a temporary directory at /tmp/tmpsm9kcd8_\n",
      "Writing /tmp/tmpsm9kcd8_/_remote_module_non_sriptable.py\n",
      "[NeMo W 2022-08-19 14:12:25 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    ds_item: train\n",
      "    prefix: train\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2022-08-19 14:12:25 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    prefix: test\n",
      "    ds_item:\n",
      "    - dev\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2022-08-19 14:12:25 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    prefix: test\n",
      "    ds_item:\n",
      "    - test\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 3\n",
      "    drop_last: false\n",
      "    pin_memory: false\n",
      "    \n",
      "[NeMo W 2022-08-19 14:12:25 nlp_overrides:228] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-08-19 14:12:30 nemo_logging:349] /home/lilee/python3/py38/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                    not been set for this class (ClassificationReport). The property determines if `update` by\n",
      "                    default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                    achieved and we recommend setting this to `False`.\n",
      "                    We provide an checking function\n",
      "                    `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                    that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                    default for now) or if `full_state_update=False` can be used safely.\n",
      "                    \n",
      "      warnings.warn(*args, **kwargs)\n",
      "    \n",
      "[NeMo I 2022-08-19 14:12:33 save_restore_connector:243] Model DialogueZeroShotSlotFillingModel was successfully restored from /home/lilee/nemo_experiments/assistant/assistant_0.5_0.5_epoch_10_lr_0.00001.nemo.\n",
      "[NeMo I 2022-08-19 14:12:33 dialogue_zero_shot_slot_filling_model:755] Setting model.dataset.data_dir to ./conll_2003/with_entity.\n",
      "[NeMo I 2022-08-19 14:12:33 dialogue_zero_shot_slot_filling_model:756] Setting model.dataset.dialogues_example_dir to ./train_assistant_test_conll2003/with_entity_prediction.\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-08-19 14:12:36 dialogue_zero_shot_slot_filling_dataset:329] Setting max length to: 128\n",
      "[NeMo I 2022-08-19 14:12:36 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-08-19 14:12:36 data_preprocessing:406] Min: 3 |                  Max: 140 |                  Mean: 19.767416545718433 |                  Median: 14.0\n",
      "[NeMo I 2022-08-19 14:12:36 data_preprocessing:412] 75 percentile: 28.00\n",
      "[NeMo I 2022-08-19 14:12:36 data_preprocessing:413] 99 percentile: 60.00\n",
      "[NeMo I 2022-08-19 14:12:36 dialogue_zero_shot_slot_filling_dataset:254] 1 are longer than 128\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Testing DataLoader 0: 100%|███████████████████| 345/345 [00:55<00:00,  6.23it/s][NeMo I 2022-08-19 14:13:48 dialogue_zero_shot_slot_filling_model:649] BIO slot report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    0 (label_id: 0)                                         89.20      82.35      85.64      38900\n",
      "    1 (label_id: 1)                                         50.27      47.62      48.91       4082\n",
      "    2 (label_id: 2)                                         42.99      66.03      52.08       5973\n",
      "    -------------------\n",
      "    micro avg                                               77.47      77.47      77.47      48955\n",
      "    macro avg                                               60.82      65.34      62.21      48955\n",
      "    weighted avg                                            80.32      77.47      78.48      48955\n",
      "    \n",
      "[NeMo I 2022-08-19 14:13:48 dialogue_zero_shot_slot_filling_model:657] Slot similarity report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    other (label_id: 0)                                      0.00       0.00       0.00          0\n",
      "    location (label_id: 1)                                  73.79      18.01      28.95       1266\n",
      "    miscellaneous (label_id: 2)                             46.13      22.20      29.98        563\n",
      "    organization (label_id: 3)                              46.01      82.57      59.09       1228\n",
      "    person (label_id: 4)                                    73.82      92.68      82.18       1025\n",
      "    -------------------\n",
      "    micro avg                                               56.76      56.76      56.76       4082\n",
      "    macro avg                                               59.93      53.87      50.05       4082\n",
      "    weighted avg                                            61.62      56.76      51.53       4082\n",
      "    \n",
      "[NeMo I 2022-08-19 14:13:48 dialogue_zero_shot_slot_filling_model:665] Overall slot report: \n",
      "    label                                                precision    recall       f1           support   \n",
      "    other (label_id: 0)                                     90.60      91.04      90.82      30551\n",
      "    location (label_id: 1)                                  31.89       7.75      12.47       1523\n",
      "    miscellaneous (label_id: 2)                             12.55      21.79      15.93        748\n",
      "    organization (label_id: 3)                              28.13      31.76      29.84       1826\n",
      "    person (label_id: 4)                                    55.49      62.01      58.57       1874\n",
      "    -------------------\n",
      "    micro avg                                               81.69      81.69      81.69      36522\n",
      "    macro avg                                               43.73      42.87      41.52      36522\n",
      "    weighted avg                                            81.63      81.69      81.32      36522\n",
      "    \n",
      "Testing DataLoader 0: 100%|███████████████████| 345/345 [01:11<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\r\n",
      "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\r\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m          bio_slot_f1           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       77.46501922607422        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m       bio_slot_precision       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       77.46501922607422        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m        bio_slot_recall         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       77.46501922607422        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m        overall_slot_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       81.69322967529297        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m     overall_slot_precision     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       81.69322967529297        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m      overall_slot_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       81.69322967529297        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m       slot_similarity_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       56.761390686035156       \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m   slot_similarity_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       56.761390686035156       \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m     slot_similarity_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       56.761390686035156       \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m        unified_slot_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       19.54190263978709        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36munified_slot_joint_goal_accuracy\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       8.925979680696662        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m     unified_slot_precision     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       20.694242864054182       \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m      unified_slot_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       18.51112723754233        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "│\u001b[36m \u001b[0m\u001b[36m            val_loss            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       1.477256178855896        \u001b[0m\u001b[35m \u001b[0m│\r\n",
      "└──────────────────────────────────┴──────────────────────────────────┘\r\n"
     ]
    }
   ],
   "source": [
    "# model.dataset.data_dir: folder to load data from\n",
    "# model.dataset.dialogues_example_dir: folder that stores predictions for each sample\n",
    "# model.nemo_path: the path that loads the pre-trained nemo model\n",
    "# fine-tuned best overall f1 score in Assistant dataset at parameter: bio_slot_loss_weight=0.5, max_epochs=10, optim.lr=0.00001\n",
    "  \n",
    "!(python NeMo/examples/nlp/dialogue/dialogue.py \\\n",
    "  do_training=False \\\n",
    "  model.dataset.data_dir=\"./conll_2003/with_entity\" \\\n",
    "  model.dataset.dialogues_example_dir=\"./train_assistant_test_conll2003/with_entity_prediction\" \\\n",
    "  model.dataset.task='zero_shot_slot_filling' \\\n",
    "  model.language_model.pretrained_model_name='bert-base-uncased' \\\n",
    "  exp_manager.create_wandb_logger=False \\\n",
    "  model.nemo_path=\"nemo_experiments/assistant/assistant_0.5_0.5_epoch_10_lr_0.00001.nemo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results pre-trained Zero Shot Slof Filling model on Assistant Dataset, transfer to CoNLL-2003 Dataset**\n",
    "\n",
    "BIO slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    0 (label_id: 0)                                         89.20      82.35      85.64      38900\n",
    "    1 (label_id: 1)                                         50.27      47.62      48.91       4082\n",
    "    2 (label_id: 2)                                         42.99      66.03      52.08       5973\n",
    "    -------------------\n",
    "    micro avg                                               77.47      77.47      77.47      48955\n",
    "    macro avg                                               60.82      65.34      62.21      48955\n",
    "    weighted avg                                            80.32      77.47      78.48      48955\n",
    "```\n",
    "Slot similarity report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    other (label_id: 0)                                      0.00       0.00       0.00          0\n",
    "    location (label_id: 1)                                  73.79      18.01      28.95       1266\n",
    "    miscellaneous (label_id: 2)                             46.13      22.20      29.98        563\n",
    "    organization (label_id: 3)                              46.01      82.57      59.09       1228\n",
    "    person (label_id: 4)                                    73.82      92.68      82.18       1025\n",
    "    -------------------\n",
    "    micro avg                                               56.76      56.76      56.76       4082\n",
    "    macro avg                                               59.93      53.87      50.05       4082\n",
    "    weighted avg                                            61.62      56.76      51.53       4082\n",
    "```\n",
    "\n",
    "Overall slot report: \n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    other (label_id: 0)                                     90.60      91.04      90.82      30551\n",
    "    location (label_id: 1)                                  31.89       7.75      12.47       1523\n",
    "    miscellaneous (label_id: 2)                             12.55      21.79      15.93        748\n",
    "    organization (label_id: 3)                              28.13      31.76      29.84       1826\n",
    "    person (label_id: 4)                                    55.49      62.01      58.57       1874\n",
    "    -------------------\n",
    "    micro avg                                               81.69      81.69      81.69      36522\n",
    "    macro avg                                               43.73      42.87      41.52      36522\n",
    "    weighted avg                                            81.63      81.69      81.32      36522\n",
    "```\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃           Test metric            ┃           DataLoader 0           ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│           bio_slot_f1            │        77.46501922607422         │\n",
    "│        bio_slot_precision        │        77.46501922607422         │\n",
    "│         bio_slot_recall          │        77.46501922607422         │\n",
    "│         overall_slot_f1          │        81.69322967529297         │\n",
    "│      overall_slot_precision      │        81.69322967529297         │\n",
    "│       overall_slot_recall        │        81.69322967529297         │\n",
    "│        slot_similarity_f1        │        56.761390686035156        │\n",
    "│    slot_similarity_precision     │        56.761390686035156        │\n",
    "│      slot_similarity_recall      │        56.761390686035156        │\n",
    "│         unified_slot_f1          │        19.54190263978709         │\n",
    "│ unified_slot_joint_goal_accuracy │        8.925979680696662         │\n",
    "│      unified_slot_precision      │        20.694242864054182        │\n",
    "│       unified_slot_recall        │        18.51112723754233         │\n",
    "│             val_loss             │        1.477256178855896         │\n",
    "└──────────────────────────────────┴──────────────────────────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Dialogue.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
